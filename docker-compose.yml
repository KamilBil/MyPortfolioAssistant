services:
  init:
    image: curlimages/curl
    depends_on:
      - ollama
    environment:
      OLLAMA_MODEL: ${OLLAMA_MODEL}
    networks:
      - rag-net
    entrypoint: >
      sh -c "
        until curl -s http://ollama:11434; do
          echo '⏳ Waiting for ollama server...';
          sleep 2;
        done;
        echo '✅ Server is running, downloading the model...';
        curl -X POST http://ollama:11434/api/pull -d '{\"name\": \"${OLLAMA_MODEL}\"}' -H 'Content-Type: application/json';
      "

  ollama:
    image: ollama/ollama:latest
    container_name: priv_ollama
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - rag-net
    expose:
      - 11434

  rag-app:
    build: .
    container_name: rag-app
    networks:
      - rag-net
    depends_on:
      - ollama
    ports:
      - "8000:8000"
    environment:
      OLLAMA_HOST: http://ollama:11434
      OLLAMA_MODEL: ${OLLAMA_MODEL}

volumes:
  ollama_data:

networks:
  rag-net:
    driver: bridge
